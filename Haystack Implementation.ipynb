{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FARM-Haystack QnA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "INPUT-autoencoded representation using pipelined vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Autoencoder\n",
    "import keras\n",
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "class Autoencoder:\n",
    "\n",
    "    def fit(self, X):\n",
    "        if not self.autoencoder:\n",
    "            self._compile(X.shape[1])\n",
    "        X_train, X_test = train_test_split(X)\n",
    "        self.his = self.autoencoder.fit(X_train, X_train,\n",
    "                                        epochs=200,\n",
    "                                        batch_size=128,\n",
    "                                        shuffle=True,\n",
    "                                        validation_data=(X_test, X_test), verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "!pip install \"git+https://github.com/deepset-ai/FARM.git@0749dcb8fb46dace0d0987d6fdedf5f28120a461\"\n",
    "!pip install \"git+https://github.com/deepset-ai/haystack.git@0cffc6cb1df8782bbf1bbc336807de355687584b\"\n",
    "!pip install ipywidgets\n",
    "!jupyter nbextension enable --py widgetsnbextension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from haystack import Finder\n",
    "from haystack.database.sql import SQLDocumentStore\n",
    "from haystack.retriever.tfidf import TfidfRetriever\n",
    "from haystack.reader.farm import FARMReader\n",
    "from haystack.utils import print_answers\n",
    "import json\n",
    "import os\n",
    "from pathlib import Path\n",
    "import re\n",
    "import tqdm\n",
    "from xml.etree import ElementTree as ET\n",
    "from zipfile import ZipFile\n",
    "\n",
    "logger = logging.getLogger(\"haystack\")\n",
    "logger.setLevel(logging.ERROR)\n",
    "\n",
    "\n",
    "def write_documents_to_db(document_store, autoencoder, clean_func=None, only_empty_db=False, \n",
    "    split_paragraphs=False, abstracts_only=False):\n",
    "    \n",
    "    # check if db has already docs\n",
    "    if only_empty_db:\n",
    "        n_docs = document_store.get_document_count()\n",
    "        if n_docs > 0:\n",
    "          \n",
    "            return None\n",
    "\n",
    "    # read and add docs\n",
    "    docs_to_index = []\n",
    "    count = 1\n",
    "   \n",
    " def get_finder(full_text, abstracts_only=False):\n",
    "   \n",
    "    document_store = SQLDocumentStore(autoencoder)\n",
    "    write_documents_to_db(document_store=document_store, \n",
    "        document_dir=data_directory, only_empty_db=True, \n",
    "        abstracts_only=abstracts_only)\n",
    "    retriever = TfidfRetriever(document_store=document_store)\n",
    "    reader = FARMReader(\n",
    "        model_name_or_path=\"deepset/bert-large-uncased-whole-word-masking-squad2\", \n",
    "        use_gpu=True)\n",
    "        #model_name_or_path=\"gdario/biobert_bioasq\", \n",
    "        #use_gpu=False)\n",
    "    finder = Finder(reader, retriever)\n",
    "    return finder\n",
    "\n",
    "class Result(object):\n",
    "    \"\"\"\n",
    "    A data structure to store question answering results (at document-section level).\n",
    "    \"\"\"\n",
    "    def __init__(self, title, url, authors, section_title, text, spans):\n",
    "       \n",
    "        self.title = title\n",
    "        self.url = url\n",
    "        self.authors = authors\n",
    "        self.section_title = section_title\n",
    "        self.text = text\n",
    "        self.spans = spans\n",
    "\n",
    "def get_results(finder, top_k_retriever, top_k_reader, candidate_doc_ids, question):\n",
    "   \n",
    "    paragraphs, meta_data = finder.retriever.retrieve(question, top_k=top_k_retriever, candidate_doc_ids=candidate_doc_ids)\n",
    "    results = []\n",
    "\n",
    "    if len(paragraphs) > 0:\n",
    "\n",
    "        # 3) Apply reader to get granular answer(s)\n",
    "        len_chars = sum([len (p) for p in paragraphs])\n",
    "        predictions = finder.reader.predict(question=question,\n",
    "            paragraphs=paragraphs,\n",
    "            meta_data_paragraphs=meta_data,\n",
    "            top_k=top_k_reader)\n",
    "\n",
    "        # Add corresponding document_name if an answer contains the document_id \n",
    "        for prediction in predictions[\"answers\"]:\n",
    "            document = finder.retriever.document_store.get_document_by_id(prediction[\"document_id\"])\n",
    "            title, section_title, authors, paper_id = document[\"name\"].split(\"|||\")\n",
    "            url = \"https://cord-19.apps.allenai.org/paper/%s\" % paper_id\n",
    "            spans = [{\n",
    "                \"start\" : prediction[\"offset_start\"], \n",
    "                \"end\" : prediction[\"offset_end\"], \n",
    "            }]\n",
    "            result = Result(\n",
    "                title, \n",
    "                url, \n",
    "                authors, \n",
    "                section_title, \n",
    "                prediction[\"context\"], \n",
    "                spans, \n",
    "            )\n",
    "            results.append(result)\n",
    "    \n",
    "    return results\n",
    "\n",
    "def add_search_result_element(container, result):\n",
    "   \n",
    "    # Title\n",
    "    div = ET.SubElement(container, \"div\")\n",
    "    a = ET.SubElement(div, \"a\", href=result.url, target=\"_blank\")\n",
    "    a.text = result.title\n",
    "\n",
    "    # Authors\n",
    "    div = ET.SubElement(container, \"div\")\n",
    "    b = ET.SubElement(div, \"b\")\n",
    "    b.text = result.authors\n",
    "\n",
    "    # Section Title\n",
    "    div = ET.SubElement(container, \"div\")\n",
    "    b = ET.SubElement(div, \"b\", style=\"color: grey;\")\n",
    "    b.text = result.section_title\n",
    "    \n",
    "    # Snippet\n",
    "    cursor = 0\n",
    "    for span in result.spans:\n",
    "        div = ET.SubElement(container, \"div\")\n",
    "        p = ET.SubElement(div, \"p\")\n",
    "        span_element = ET.SubElement(p, \"span\")\n",
    "        span_element.text = result.text[:span[\"start\"]]\n",
    "        span_element = ET.SubElement(p, \"span\", style=\"background-color: #DCDCDC; border-radius: 5px; padding: 5px;\")\n",
    "        span_element.text = result.text[span[\"start\"]:span[\"end\"]]\n",
    "        cursor = span[\"end\"]\n",
    "    if cursor < len(result.text):\n",
    "        span_element = ET.SubElement(p, \"span\")\n",
    "        span_element.text = result.text[cursor:]\n",
    "\n",
    "def generate_html(question, results):\n",
    "   \n",
    "    container = ET.Element(\"div\")\n",
    "    \n",
    "    # Add question\n",
    "    div = ET.SubElement(container, \"div\")\n",
    "    h = ET.SubElement(div, \"h1\")\n",
    "    h.text = question\n",
    "    \n",
    "    # Add answers\n",
    "    for result in results:\n",
    "        add_search_result_element(container, result)\n",
    "        ET.SubElement(container, \"hr\")\n",
    "    html = str(ET.tostring(container))[2:-1]\n",
    "    return html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finder = get_finder(\"/kaggle/input/\", abstracts_only=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_k_retriever = 50\n",
    "top_k_reader = 5\n",
    "candidate_doc_ids = None\n",
    "questions = [\n",
    "    \n",
    "  \n",
    "   \n",
    "    \"Is there any difference in symptoms of coronavirus disease for pregnant women ?\",\n",
    "   \"What are the Treatment Options for Pregnant Women Infected with COVID-19 ? \",\n",
    "     \"Is there any difference in symptoms of coronavirus disease for neonates?\",\n",
    "     \"Who is most at risk for COVID-19 pregnant women or non-pregnant women?\",\n",
    "     \"How can pregnant women protect themselves against COVID-19?\",\n",
    "   \"Do pregnant women with suspected or confirmed COVID-19 need to give birth by caesarean section?\",\n",
    "    \"Can COVID-19 be passed from a woman to her unborn or newborn baby?\",\n",
    "    \"What are considerations for neonates at risk for COVID-19?\",\n",
    "    \"Will COVID-19 be transmitted vertically to the fetus from the pregnant mother \"\n",
    "    \"will pregnant or recently pregnant women with COVID-19 give birth prematurely?\",\n",
    "    \"What are the risks for pregnant women with COVID-19 alongside other co-morbidities?\",\n",
    "  \"Will I be able to breastfeed my baby if I have suspected or confirmed coronavirus?\"\n",
    "\n",
    "\n",
    "  \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import display\n",
    "from IPython.core.display import HTML\n",
    "from IPython.utils import io\n",
    "\n",
    "html_string = \"\"\n",
    "for question in questions:\n",
    "    with io.capture_output() as captured:\n",
    "        results = get_results(finder, top_k_retriever, top_k_reader, candidate_doc_ids, question)\n",
    "    current_html_string = generate_html(question, results)\n",
    "    html_string += current_html_string\n",
    "    display(HTML(current_html_string))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
